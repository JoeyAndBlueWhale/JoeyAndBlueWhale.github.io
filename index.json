
    
    
    
    
    [{"authors":["admin"],"categories":null,"content":"I’m a third year PhD student at UT Austin under the supervision of Eric Price. Before I was a Master student at UBC and was co-supervised by Nick Harvey and Mark Schmidt.\nRecently I’m studying active learning. Specifically, we’re working on designing Bayesian active learning methods with near-optimal theoretical gurantees. During my Master’s studies, my research revolved around first-order optimization methods and online learning. I am also interested in data-driven algorithms and differential privacy. More generally, I work on learning theory and like TCS problems. If you want to collaborate or even just chat with me, please send me an email!\n“I’m one with the force and the force is with me.” – Chirrut Îmwe\nMore About Me This section is just a random walk of the thoughts in my head. (Yes, randomness is vital in algorithm design!)\nI have a ton of hobbies, but I\u0026#39;m not really good at any of them. I enjoy poems, movies and literature. García Márquez is my favorite writer. Edward Yang is my favourite movie director. I watch and play soccer and basketball. I watch Dota 2 tournaments (not play the game anymore though). I support Liverpool and Inter Milan in soccer and Toronto Raptors in basketball.\nPolitical activism is important. Fighting for the rights of underprivileged groups and against authoritarianism is everyone\u0026#39;s duty. For example, we should all remember this as one of the worst atrocities against humanity in the 21st century.\nCanada \u0026gt;\u0026gt; United States. Genshin Impact is a bad game. My favourite Star Wars character is Karis Nemik.\nOccasionally, I write short stories here. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a third year PhD student at UT Austin under the supervision of Eric Price. Before I was a Master student at UBC and was co-supervised by Nick Harvey and Mark Schmidt.","tags":null,"title":"Yihan Zhou (Joey)","type":"authors"},{"authors":["Eric Price","Yihan Zhou"],"categories":null,"content":"","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"2c40154fc78c0846c4c57efcdccd39a3","permalink":"https://joeyandbluewhale.github.io/publication/activebiclass/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/publication/activebiclass/","section":"publication","summary":"For some hypothesis classes and input distributions, active agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs. We take a different approach to agnostic active learning, getting an algorithm that is competitive with the optimal algorithm for any binary hypothesis class {{\u003c math \u003e}}$H${{\u003c /math \u003e}} and distribution {{\u003c math \u003e}}$\\mathcal{D}_X${{\u003c /math \u003e}} over {{\u003c math \u003e}}$X${{\u003c /math \u003e}}. In particular, if any algorithm can use {{\u003c math \u003e}}$m^*${{\u003c /math \u003e}} queries to get {{\u003c math \u003e}}$O(\\eta)${{\u003c /math \u003e}} error, then our algorithm uses {{\u003c math \u003e}}$O(m^*\\log |H|)${{\u003c /math \u003e}} queries to get {{\u003c math \u003e}}$O(\\eta)${{\u003c /math \u003e}} error. Our algorithm lies in the vein of the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ({{\u003c math \u003e}}$\\eta=0${{\u003c /math \u003e}} ) setting. We also show that it is NP-hard to do better than our algorithm's {{\u003c math \u003e}}$O(\\log|H|)${{\u003c /math \u003e}} overhead in general. ","tags":null,"title":"A Competitive Algorithm for Agnostic Active Learning (NeurIPS 2023)","type":"publication"},{"authors":["Amrutha Varshini Ramesh","Aaron Mishkin","Mark Schmidt","Yihan Zhou","Jonathan Wilder Lavington","Jennifer She"],"categories":null,"content":"","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"faeeb3c1c0e64f6872de69ea735bfde3","permalink":"https://joeyandbluewhale.github.io/publication/coordinatedescent/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/publication/coordinatedescent/","section":"publication","summary":"We consider minimizing a smooth function subject to a summation constraint over its variables. By exploiting a connection between the greedy 2-coordinate update for this problem and equality-constrained steepest descent in the 1-norm, we give a convergence rate for greedy selection under a proximal Polyak-Lojasiewicz assumption that is faster than random selection and independent of the problem dimension n. We then consider minimizing with both a summation constraint and bound constraints, as arises in the support vector machine dual problem. Existing greedy rules for this setting either guarantee trivial progress only or require {{\u003c math \u003e}}$O(n^2)${{\u003c /math \u003e}} time to compute. We show that bound and summation-constrained steepest descent in the L1-norm guarantees more progress per iteration than previous rules and can be computed in only {{\u003c math \u003e}}$O(n\\log n)${{\u003c /math \u003e}} time.","tags":null,"title":"Analyzing and Improving Greedy 2-Coordinate Updates For Equality-Constrained Optimization via Steepest Descent in the 1-Norm","type":"publication"},{"authors":["Yihan Zhou","Victor Portella","Mark Schmidt","Nick Harvey"],"categories":null,"content":"","date":1598572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598572800,"objectID":"09f3492501d555be372cafed0eb0dccc","permalink":"https://joeyandbluewhale.github.io/publication/relativelip/","publishdate":"2020-08-28T00:00:00Z","relpermalink":"/publication/relativelip/","section":"publication","summary":"Online convex optimization (OCO) is a powerful algorithmic framework that has extensive applications in different areas. Regret is a commonly-used measurement for the performance of algorithms in this framework. Lipschitz continuity of the cost functions is commonly assumed in order to obtain sublinear regret, that is to say, this condition is usually necessary for theoretical guarantees for good performances of OCO algorithms. Moreover, strong convexity of cost functions can sometimes give even better theoretical performance bounds, more specifically, logarithmic regret. Recently, researchers from convex optimization proposed the notions of \"relative Lipschitz continuity\" and \"relative strong convexity\". Both of the notions are generalizations of their classical counterparts. It has been shown that subgradient methods in the relative setting have performance analogous to their performance in the classical setting. In this work, we consider OCO for relative Lipschitz and relative strongly convex functions. We extend the known regret bounds for classical OCO algorithms to the relative setting. Specifically, we show regret bounds for the follow the regularized leader algorithms and a variant of online mirror descent. Due to the generality of these methods, these results yield regret bounds for a wide variety of OCO algorithms. Furthermore, we extend the results to algorithms with extra regularization such as regularized dual averaging.","tags":null,"title":"Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses (NeurIPS 2020)","type":"publication"},{"authors":["John-Jose Nunez","Teyden T. Nguyen","Yihan Zhou","Bo Cao","Raymond T. Ng","Jun Chen","Benicio N. Frey","Roumen Milev","Daniel J. Müller","Susan Rotzinger","Claudio N. Soares","Rudolf Uher","Sidney H. Kennedy","Raymond W. Lam"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"d318660e444b63c5ea06f780e9fc4447","permalink":"https://joeyandbluewhale.github.io/publication/antidepressant/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/antidepressant/","section":"publication","summary":"Antidepressants are first-line treatments for major depressive disorder (MDD), but 40-60% of patients will not respond, hence, predicting response would be a major clinical advance. Machine learning algorithms hold promise to predict treatment outcomes based on clinical symptoms and episode features. We sought to independently replicate recent machine learning methodology predicting antidepressant outcomes using the Sequenced Treatment Alternatives to Relieve Depression (STAR*D) dataset, and then externally validate these methods to train models using data from the Canadian Biomarker Integration Network in Depression (CAN-BIND-1) dataset.","tags":null,"title":"Replication of machine learning methods to predict treatment outcome with antidepressant medications in patients with major depressive disorder from STAR*D and CAN-BIND-1 (PLOS ONE)","type":"publication"}]