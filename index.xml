<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joey&#39;s Homepage</title>
    <link>https://JoeyAndBlueWhale.github.io/</link>
      <atom:link href="https://JoeyAndBlueWhale.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Joey&#39;s Homepage</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>https://JoeyAndBlueWhale.github.io/img/icon-512.png</url>
      <title>Joey&#39;s Homepage</title>
      <link>https://JoeyAndBlueWhale.github.io/</link>
    </image>
    
    <item>
      <title>Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses (NeurIPS 2020)</title>
      <link>https://JoeyAndBlueWhale.github.io/publication/relativelip/</link>
      <pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/publication/relativelip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sample Complexity of the Linear Quadratic Regulator</title>
      <link>https://JoeyAndBlueWhale.github.io/talk/samplecomplexitylqr/</link>
      <pubDate>Wed, 05 Aug 2020 13:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/talk/samplecomplexitylqr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improved Analyses of Block-Coordinate Descent for Linearly-Constrained, Composite Objectives</title>
      <link>https://JoeyAndBlueWhale.github.io/publication/coordinatedescent/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/publication/coordinatedescent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Replication of Machine-Learning Analyses to Predict Response to Antidepressant Medications in Patients with Major Depressive Disorder</title>
      <link>https://JoeyAndBlueWhale.github.io/publication/antidepressant/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/publication/antidepressant/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Generalization of Kernel Learning</title>
      <link>https://JoeyAndBlueWhale.github.io/talk/kernellearning/</link>
      <pubDate>Wed, 20 Nov 2019 13:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/talk/kernellearning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Online Learning and Bandits</title>
      <link>https://JoeyAndBlueWhale.github.io/talk/onlinelearning/</link>
      <pubDate>Wed, 19 Jun 2019 17:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/talk/onlinelearning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dictionary Learning</title>
      <link>https://JoeyAndBlueWhale.github.io/talk/dictionarylearning/</link>
      <pubDate>Mon, 15 Apr 2019 17:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/talk/dictionarylearning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning Algorithms for White Balancing</title>
      <link>https://JoeyAndBlueWhale.github.io/project/whitebalance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/project/whitebalance/</guid>
      <description>&lt;p&gt;This is a part time URA(Undergrad Research Assistant) I did with Professor Peter Van Beek. White balance is a vital step in image processing. Due to computation limitations, current white balancing algorithms for cameras are simple. But if we ignore this restriction and apply ML algorithms, state-of-arts performance can be achieved. We explored different machine learning/deep learning methods to improve white balancing performance for photo processing.&lt;/p&gt;
&lt;p&gt;I implemented some popular data augmentation tricks and domain-adaptation
heuristics in MATLAB on existing algorithm and improved the performance
slightly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy in Machine Learning</title>
      <link>https://JoeyAndBlueWhale.github.io/project/mlprivacy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/project/mlprivacy/</guid>
      <description>&lt;p&gt;We conduct a survey on privacy in machine learning. First we show examples of how people could use machine learning to invade privacy and how machine learning could cause some unprecedented privacy issues. Then we give the rigorous definition of privacy in mathematics. In the end of this paper, we demonstrate three specific privacy preserving machine learning algorithms and one noise generation method.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Private Sequential Learning</title>
      <link>https://JoeyAndBlueWhale.github.io/project/privatesequentiallearning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/project/privatesequentiallearning/</guid>
      <description>&lt;p&gt;The query complexity of the learner in the presence of an adversary is investigated in Tsitsiklis et al. In this work, it is assumed that the adversary gets to observe all the learners queries but is oblivious to the responses that the learner gets for each query. Tsitsiklis et al also introduces the same problem under the bayesian setting and provides bounds on the query complexity when operating under a uniform prior over the queried values. We provide tighter bounds for this case thus managing to improve both the upper and lower bound on the query complexity. For the upper bound, we propose a new algorithm that is better than replicated bisection search under certain assumptions of the value of parameters. In addition we improve the lower bound with an additive factor. We also investigate the private query model in higher dimension, which is mentioned as one of the open problems in Tsitsiklis et al. We successfully extend the opportunistic bisection strategy to higher dimension and derive an upper bound based on the strategy. We use the same method as in Tsitsiklis et al to prove the lower bound with a strengthened accuracy constraint and derive a less tighter lower bound with the original accuracy constraint.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Replicating and Improving the Prediction of Antidepressant Response Using the CAN-BIND and STAR*D Datasets</title>
      <link>https://JoeyAndBlueWhale.github.io/project/antidep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/project/antidep/</guid>
      <description>&lt;p&gt;This is a course project led by a medical student. We replicated a study using ML algorithms for the prediction of antidepressant response on a new dataset and tested various new ML models on this task. I implemented all the ML models. We have already submitted the paper to a medical journal. The project report is not published here due to confidentiality of the medical dataset used.&lt;/p&gt;
&lt;p&gt;Major depressive disorder (MDD) is the second-leading cause of disability globally. This depressive disorder is marked by low mood, anhedonia (inability to experience joy) and neurovegetative symptoms such as low energy, poor concentration, and over- or under-sleeping. The condition can affects all aspects of life, from hampering or even preventing work, to increasing mortality from other medical conditions. Understandably, depression is a common reason to access healthcare, and is associated with significant healthcare costs.&lt;/p&gt;
&lt;p&gt;The mainstay and first-line therapy physicians use for MDD remains prescribing an antidepressant, a variety of medications of different mechanisms. While effective, only a little over half of patients will respond to this initial therapy, and many will need to try a different agent. Many options are available for patients who do not respond to initial treatment with an antidepressant, though it can takes months of trial and error until these options are attempted.&lt;/p&gt;
&lt;p&gt;This presents a promising application for predictive modelling. If a patient can be predicted to have a high chance of not responding to treatment with an antidepressant, treatment outcomes may be improved by giving these patients more aggressive therapy sooner. For example, a high-risk patient might benefit from having a second, adjunctive medication right away, or may be prioritized to also engage in psychotherapy (counselling). Both have been shown to increase depression response rates, but have barriers to be used widely such as costs or side-effects.&lt;/p&gt;
&lt;p&gt;Our projects seeks to continue this work improving the prediction of antidepressant response from clinical data. We do this in three ways: creating a reproducible, transparent, and reusable automated method for data processing, replicating the recent work by Nie et al. and externally validating their model on a new dataset, and by testing new, previously unpublished methods for both prediction and feature selection.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variants of Frank-Wolfe algorithm</title>
      <link>https://JoeyAndBlueWhale.github.io/project/frankwolfe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://JoeyAndBlueWhale.github.io/project/frankwolfe/</guid>
      <description>&lt;p&gt;This is a part time URA (Undergrad Research Assistant) supervised by Yaoliang Yu. Frank-Wolfe algorithm is a first-order optimization algorithm for constraint optimization problems. The per iteration cost for Frank-Wolfe algorithm is low because it doesn&amp;rsquo;t need the projection step. Recently this algorithm has gained attention again. This project involves in a study of this algorithm and its variants. We also attempted to relax the constraints of some of them.&lt;/p&gt;
&lt;p&gt;I simplified one algorithm and provided a simpler proof.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
